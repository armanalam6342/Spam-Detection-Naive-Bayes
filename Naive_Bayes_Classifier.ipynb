{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes Classifier.ipynb",
      "provenance": [],
      "mount_file_id": "1pZB8-dJyi-UfagiF_ny-rhF7TDP-_I01",
      "authorship_tag": "ABX9TyMKemoJbiGBl82Pt9sA7/zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armanalam6342/Spam-Detection-Naive-Bayes/blob/main/Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayi53v8TO-uW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emBHWFJ_OtDk"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/housing data/spam.csv\",encoding='ISO-8859-1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "o50QnAxwPExT",
        "outputId": "92e4a08e-f17e-4b2f-86bc-781d72959cd1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88TmaneaPQcK"
      },
      "source": [
        "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "AurgcASfPpcp",
        "outputId": "7dd66352-81c8-4bca-d051-687844a692d3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5EYA4aKPzJo"
      },
      "source": [
        "df.rename(columns={'v1':'label','v2':'message'},inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATg4Am0_Q0jW",
        "outputId": "d6bf4380-9de6-484f-e5e8-bdc86743dbeb"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hppk9O2RIVu",
        "outputId": "3d6e49fd-3503-4ed3-c0be-3d6dbe9246c0"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP_HVPKGROOl",
        "outputId": "3d77f584-cc16-4f20-ebe1-0476bfcb40ab"
      },
      "source": [
        "len(df['message'][0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBgNH9FJRakV"
      },
      "source": [
        "df['length']=df['message'].apply(len)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlcZt2g2SEcO"
      },
      "source": [
        "Bag of words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBHZ2OBDRuas"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcdVodYzS-Yx",
        "outputId": "f7651b59-7963-46ac-de9f-5d575f74e5a1"
      },
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TehdUYE4TGa4"
      },
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq6opzHOTgHM",
        "outputId": "9768ea18-31f4-4e99-b21c-45d8105999bf"
      },
      "source": [
        "stopwords.words(\"english\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PgAmG3TTgjY",
        "outputId": "a31a6135-21f1-4f59-9a6e-a841b07bacaa"
      },
      "source": [
        "[i for i in string.punctuation]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbnOzGOGX1q4"
      },
      "source": [
        "## removing Stop words and punctuation from message"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IRyWs9JWWS1"
      },
      "source": [
        "def msg_process(msg):\n",
        "  nopunc= [i for i in msg if i not in string.punctuation]\n",
        "  nopunc= ''.join(nopunc)\n",
        "  stop = [i for i in nopunc.split() if i.lower() not in stopwords.words('english')]\n",
        "  return ' '.join(stop)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIsnC0FyYZwv"
      },
      "source": [
        "## tokenized message when we remove these words its process name is tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiLWih79UGIm"
      },
      "source": [
        "df['tokenized_msg']=df['message'].apply(msg_process)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DbRQFxhnUjF-",
        "outputId": "ce7fab02-f920-4419-c5ab-d9da6dcbe92b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>length</th>\n",
              "      <th>tokenized_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "      <td>U dun say early hor U c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "      <td>Nah dont think goes usf lives around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                      tokenized_msg\n",
              "0   ham  ...  Go jurong point crazy Available bugis n great ...\n",
              "1   ham  ...                            Ok lar Joking wif u oni\n",
              "2  spam  ...  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
              "3   ham  ...                U dun say early hor U c already say\n",
              "4   ham  ...        Nah dont think goes usf lives around though\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlLSA114Yxac"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIe5dFB3ctQa"
      },
      "source": [
        "vectorizer = CountVectorizer(max_df=0.9,min_df=10)\n",
        "X = vectorizer.fit_transform(df['tokenized_msg'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_TYhiUKdWN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b03438a-7d72-40c7-b05d-f2e16deee522"
      },
      "source": [
        "X.toarray().shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 872)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "hNuL8jGRKHbP",
        "outputId": "586e5bc1-88e5-403a-d745-4e3238144c65"
      },
      "source": [
        "pd.DataFrame(X.toarray() , columns=vectorizer.get_feature_names()).head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0800</th>\n",
              "      <th>08000839402</th>\n",
              "      <th>08000930705</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10p</th>\n",
              "      <th>12</th>\n",
              "      <th>12hrs</th>\n",
              "      <th>150</th>\n",
              "      <th>150p</th>\n",
              "      <th>150pm</th>\n",
              "      <th>150pmsg</th>\n",
              "      <th>150ppm</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>1st</th>\n",
              "      <th>200</th>\n",
              "      <th>2000</th>\n",
              "      <th>2003</th>\n",
              "      <th>250</th>\n",
              "      <th>2nd</th>\n",
              "      <th>300</th>\n",
              "      <th>350</th>\n",
              "      <th>500</th>\n",
              "      <th>5000</th>\n",
              "      <th>750</th>\n",
              "      <th>800</th>\n",
              "      <th>8007</th>\n",
              "      <th>86688</th>\n",
              "      <th>87066</th>\n",
              "      <th>abiola</th>\n",
              "      <th>able</th>\n",
              "      <th>abt</th>\n",
              "      <th>account</th>\n",
              "      <th>across</th>\n",
              "      <th>actually</th>\n",
              "      <th>address</th>\n",
              "      <th>admirer</th>\n",
              "      <th>aft</th>\n",
              "      <th>...</th>\n",
              "      <th>wit</th>\n",
              "      <th>within</th>\n",
              "      <th>without</th>\n",
              "      <th>wk</th>\n",
              "      <th>wkly</th>\n",
              "      <th>woke</th>\n",
              "      <th>wonder</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>wont</th>\n",
              "      <th>word</th>\n",
              "      <th>words</th>\n",
              "      <th>work</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worry</th>\n",
              "      <th>worth</th>\n",
              "      <th>wot</th>\n",
              "      <th>would</th>\n",
              "      <th>wow</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>xmas</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxx</th>\n",
              "      <th>ya</th>\n",
              "      <th>yar</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>yo</th>\n",
              "      <th>youll</th>\n",
              "      <th>youre</th>\n",
              "      <th>youve</th>\n",
              "      <th>yr</th>\n",
              "      <th>yup</th>\n",
              "      <th>ìï</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 872 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0800  08000839402  08000930705  10  100  ...  youre  youve  yr  yup  ìï\n",
              "0     0            0            0   0    0  ...      0      0   0    0   0\n",
              "1     0            0            0   0    0  ...      0      0   0    0   0\n",
              "2     0            0            0   0    0  ...      0      0   0    0   0\n",
              "3     0            0            0   0    0  ...      0      0   0    0   0\n",
              "4     0            0            0   0    0  ...      0      0   0    0   0\n",
              "\n",
              "[5 rows x 872 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "TLXzdgvLLVQ9",
        "outputId": "90590d1f-933c-4098-c626-69e64ba5e3a0"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "      <th>length</th>\n",
              "      <th>tokenized_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                      tokenized_msg\n",
              "0   ham  ...  Go jurong point crazy Available bugis n great ...\n",
              "1   ham  ...                            Ok lar Joking wif u oni\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0s2WV5tDUIb",
        "outputId": "bbabe626-a4eb-41eb-b556-2a3ad5ae8d6f"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0800', '08000839402', '08000930705', '10', '100', '1000', '10p', '12', '12hrs', '150', '150p', '150pm', '150pmsg', '150ppm', '16', '18', '1st', '200', '2000', '2003', '250', '2nd', '300', '350', '500', '5000', '750', '800', '8007', '86688', '87066', 'abiola', 'able', 'abt', 'account', 'across', 'actually', 'address', 'admirer', 'aft', 'afternoon', 'age', 'ago', 'ah', 'aight', 'almost', 'alone', 'already', 'alright', 'also', 'always', 'amp', 'angry', 'another', 'ans', 'answer', 'anyone', 'anything', 'anytime', 'anyway', 'apply', 'ard', 'area', 'around', 'asap', 'ask', 'askd', 'asked', 'asking', 'ass', 'attempt', 'auction', 'available', 'await', 'award', 'awarded', 'away', 'awesome', 'b4', 'babe', 'baby', 'back', 'bad', 'bank', 'bath', 'bathe', 'bcoz', 'bday', 'beautiful', 'bed', 'believe', 'best', 'better', 'big', 'birthday', 'bit', 'bonus', 'book', 'booked', 'bored', 'bout', 'box', 'boy', 'boytoy', 'break', 'bring', 'brother', 'bslvyl', 'bt', 'bus', 'busy', 'buy', 'call', 'called', 'caller', 'calling', 'calls', 'camcorder', 'came', 'camera', 'cant', 'car', 'card', 'care', 'carlos', 'case', 'cash', 'cause', 'chance', 'change', 'charge', 'charged', 'chat', 'cheap', 'check', 'checking', 'chennai', 'chikku', 'choose', 'christmas', 'claim', 'class', 'close', 'club', 'code', 'collect', 'collection', 'college', 'colour', 'come', 'comes', 'comin', 'coming', 'comp', 'company', 'complimentary', 'computer', 'confirm', 'congrats', 'congratulations', 'contact', 'content', 'cool', 'correct', 'cos', 'cost', 'could', 'couple', 'course', 'coz', 'crave', 'crazy', 'credit', 'cs', 'cum', 'currently', 'customer', 'cut', 'da', 'dad', 'darlin', 'darren', 'dat', 'date', 'dating', 'day', 'days', 'de', 'dear', 'decided', 'deep', 'del', 'delivery', 'den', 'details', 'didnt', 'die', 'different', 'difficult', 'dinner', 'direct', 'dis', 'discount', 'dnt', 'doesnt', 'doin', 'done', 'dont', 'double', 'download', 'draw', 'dreams', 'drink', 'drive', 'driving', 'drop', 'drugs', 'dude', 'dun', 'dunno', 'earlier', 'early', 'easy', 'eat', 'eg', 'eh', 'either', 'else', 'em', 'email', 'end', 'ends', 'enjoy', 'enough', 'enter', 'entered', 'entry', 'etc', 'eve', 'even', 'evening', 'ever', 'every', 'everyone', 'everything', 'ex', 'exam', 'expires', 'extra', 'face', 'fact', 'family', 'fancy', 'fantastic', 'far', 'fast', 'feel', 'feeling', 'felt', 'film', 'final', 'finally', 'find', 'fine', 'finish', 'finished', 'first', 'fone', 'food', 'forget', 'forgot', 'found', 'fr', 'free', 'freemsg', 'fri', 'friday', 'friend', 'friends', 'friendship', 'frm', 'frnd', 'frnds', 'fuck', 'fucking', 'full', 'fun', 'game', 'games', 'gas', 'gave', 'gd', 'get', 'gets', 'getting', 'gift', 'girl', 'girls', 'give', 'glad', 'go', 'god', 'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodmorning', 'got', 'gotta', 'gr8', 'great', 'grins', 'guaranteed', 'gud', 'guess', 'guy', 'guys', 'gym', 'ha', 'haf', 'haha', 'hair', 'half', 'hand', 'happen', 'happened', 'happiness', 'happy', 'hard', 'hav', 'havent', 'head', 'hear', 'heard', 'heart', 'hee', 'hell', 'hello', 'help', 'hes', 'hey', 'hi', 'hit', 'hmm', 'hold', 'holiday', 'home', 'hope', 'hospital', 'hot', 'hour', 'hours', 'house', 'hows', 'huh', 'hungry', 'hurt', 'id', 'identifier', 'ill', 'im', 'immediately', 'important', 'india', 'info', 'information', 'invited', 'ipod', 'isnt', 'ive', 'jay', 'job', 'join', 'jus', 'juz', 'kate', 'keep', 'kind', 'kiss', 'knew', 'know', 'knows', 'knw', 'land', 'landline', 'laptop', 'lar', 'last', 'late', 'later', 'latest', 'laugh', 'ldn', 'least', 'leave', 'leaves', 'leaving', 'left', 'leh', 'lei', 'lesson', 'let', 'lets', 'liao', 'life', 'light', 'like', 'line', 'link', 'listen', 'little', 'live', 'loads', 'log', 'lol', 'long', 'look', 'looking', 'lor', 'lose', 'lost', 'lot', 'lots', 'lovable', 'love', 'loved', 'lovely', 'loving', 'ltd', 'ltdecimalgt', 'ltgt', 'luck', 'lucky', 'lunch', 'luv', 'made', 'mah', 'mail', 'make', 'makes', 'making', 'man', 'many', 'march', 'match', 'mate', 'mates', 'may', 'mayb', 'maybe', 'mean', 'means', 'meant', 'meet', 'meeting', 'message', 'messages', 'met', 'might', 'min', 'mind', 'mine', 'mins', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mm', 'mob', 'mobile', 'mobiles', 'mobileupd8', 'mom', 'moment', 'monday', 'money', 'month', 'months', 'morning', 'motorola', 'move', 'movie', 'mr', 'mrng', 'msg', 'msgs', 'mu', 'much', 'mum', 'music', 'must', 'muz', 'nah', 'name', 'national', 'need', 'needs', 'network', 'neva', 'never', 'new', 'news', 'next', 'ni8', 'nice', 'night', 'nite', 'noe', 'nokia', 'nope', 'nothing', 'nt', 'ntt', 'number', 'numbers', 'offer', 'offers', 'office', 'oh', 'ok', 'okay', 'okie', 'old', 'one', 'ones', 'online', 'oops', 'open', 'operator', 'opt', 'orange', 'orchard', 'order', 'oredi', 'oso', 'otherwise', 'outside', 'pa', 'pain', 'parents', 'park', 'part', 'party', 'pass', 'pay', 'people', 'per', 'person', 'phone', 'phones', 'pic', 'pick', 'picking', 'pics', 'place', 'plan', 'plans', 'play', 'player', 'please', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'point', 'points', 'poly', 'post', 'pounds', 'press', 'pretty', 'price', 'princess', 'private', 'prize', 'prob', 'probably', 'problem', 'project', 'pub', 'put', 'question', 'questions', 'quite', 'quiz', 'rate', 'rates', 'reach', 'reached', 'read', 'reading', 'ready', 'real', 'really', 'reason', 'receive', 'remember', 'remove', 'rental', 'reply', 'representative', 'right', 'ring', 'ringtone', 'rite', 'room', 'rply', 'run', 'sad', 'sae', 'safe', 'said', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says', 'sch', 'school', 'sea', 'search', 'second', 'secret', 'see', 'seeing', 'seen', 'selected', 'semester', 'send', 'sending', 'sent', 'service', 'services', 'set', 'sex', 'sexy', 'shall', 'shes', 'shit', 'shop', 'shopping', 'show', 'shower', 'shows', 'side', 'sim', 'simple', 'since', 'sir', 'sis', 'sister', 'sleep', 'sleeping', 'slow', 'slowly', 'small', 'smile', 'smiling', 'smoke', 'sms', 'smth', 'snow', 'somebody', 'someone', 'something', 'somewhere', 'song', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'speak', 'special', 'spend', 'st', 'start', 'started', 'statement', 'stay', 'still', 'stop', 'store', 'story', 'stuff', 'stupid', 'sun', 'support', 'supposed', 'sure', 'surprise', 'sweet', 'swing', 'take', 'takes', 'taking', 'talk', 'talking', 'tc', 'tcs', 'tel', 'tell', 'telling', 'ten', 'terms', 'test', 'text', 'texts', 'th', 'thank', 'thanks', 'thanx', 'thats', 'theres', 'thing', 'things', 'think', 'thinking', 'thinks', 'thk', 'tho', 'though', 'thought', 'tickets', 'til', 'till', 'time', 'times', 'tired', 'tmr', 'today', 'todays', 'together', 'told', 'tomo', 'tomorrow', 'tone', 'tones', 'tonight', 'took', 'top', 'tot', 'touch', 'town', 'treat', 'tried', 'trip', 'true', 'truth', 'try', 'trying', 'tscs', 'tv', 'two', 'txt', 'txting', 'txts', 'type', 'ugh', 'uk', 'uks', 'uncle', 'understand', 'unlimited', 'unredeemed', 'unsubscribe', 'update', 'ur', 'ure', 'urgent', 'us', 'use', 'used', 'usf', 'valentines', 'valid', 'valued', 'via', 'video', 'visit', 'voice', 'voucher', 'vouchers', 'wait', 'waiting', 'wake', 'walk', 'wan', 'wana', 'wanna', 'want', 'wanted', 'wants', 'warm', 'wasnt', 'wat', 'watch', 'watching', 'water', 'wats', 'way', 'wed', 'week', 'weekend', 'weekends', 'weekly', 'weeks', 'welcome', 'well', 'wen', 'went', 'whatever', 'whats', 'whenever', 'whole', 'whos', 'wid', 'wif', 'wife', 'wil', 'win', 'wine', 'winner', 'wish', 'wishing', 'wit', 'within', 'without', 'wk', 'wkly', 'woke', 'wonder', 'wonderful', 'wont', 'word', 'words', 'work', 'working', 'world', 'worry', 'worth', 'wot', 'would', 'wow', 'write', 'wrong', 'xmas', 'xx', 'xxx', 'ya', 'yar', 'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yet', 'yo', 'youll', 'youre', 'youve', 'yr', 'yup', 'ìï']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwmIydBuJaMQ",
        "outputId": "3a18d2fa-1040-40a3-c446-3d5139675f09"
      },
      "source": [
        "len(vectorizer.get_feature_names())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "872"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYNAzMn5dQR6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IwzqetoDLN_"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(df['tokenized_msg'],df['label'], test_size=0.20,random_state = 2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u3RdpFALjGH"
      },
      "source": [
        "X_train = vectorizer.transform(x_train).toarray()\n",
        "X_test = vectorizer.transform(x_test).toarray()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWI4PwqPL4fX",
        "outputId": "0e9b1cbc-24e5-4e87-e58d-43663a290cd6"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1iGdkE-MCy9"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxmrgkZsNALy",
        "outputId": "7f6fd678-4931-4645-b6b5-ebb7dc4762ea"
      },
      "source": [
        "naive = GaussianNB()\n",
        "naive.fit(X_train,y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSJAGTr0NXgK"
      },
      "source": [
        "test_pred= naive.predict(X_test)\n",
        "train_pred = naive.predict(X_train)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saJ3Rm_9NyOh"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6guS4YhN2QY",
        "outputId": "4f3e419b-f3f3-48ab-d2e0-b3e8dc53bcab"
      },
      "source": [
        "confusion_matrix(y_train,train_pred)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2928,  940],\n",
              "       [   0,  589]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOT_otGCN59Q",
        "outputId": "f18b6a18-5fed-4be8-b43a-4cf65196f783"
      },
      "source": [
        "confusion_matrix(y_test,test_pred)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[722, 235],\n",
              "       [ 15, 143]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwFZqxN6OPGf",
        "outputId": "c07101bb-aa82-4a33-b3eb-b8d4a31299c9"
      },
      "source": [
        "print(classification_report(y_test,test_pred))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.75      0.85       957\n",
            "        spam       0.38      0.91      0.53       158\n",
            "\n",
            "    accuracy                           0.78      1115\n",
            "   macro avg       0.68      0.83      0.69      1115\n",
            "weighted avg       0.89      0.78      0.81      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZjvsPLPOhh_"
      },
      "source": [
        "from scipy.sparse import csr_matrix"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQgtRNcMPVFj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}